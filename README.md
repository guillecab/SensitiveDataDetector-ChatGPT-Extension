# ğŸ›¡ï¸ LLM Guard Extension

ExtensiÃ³n de navegador y entorno de evaluaciÃ³n diseÃ±ados para **detectar datos sensibles** en interacciones con modelos de lenguaje (LLMs).  
El proyecto se compone de dos mÃ³dulos principales:

- **LLM_Guard_Extension/** â†’ CÃ³digo de la extensiÃ³n de navegador + servidor backend para proteger la privacidad del usuario en ChatGPT.  
- **TEST/** â†’ Experimentos de evaluaciÃ³n comparando 5 LLMs en la tarea de detecciÃ³n de informaciÃ³n sensible.

---

## ğŸš€ CaracterÃ­sticas principales

- **ExtensiÃ³n de navegador (Chromium-based)**  
  - Compatible con **Google Chrome**, **Microsoft Edge** y **Brave**.  
  - Intercepta los mensajes escritos por el usuario, los **PDF adjuntos** y las **respuestas generadas por ChatGPT**.  
  - Resalta y clasifica datos sensibles detectados en **tiempo real**.  
  - Panel flotante interactivo que muestra:  
    - Nivel de riesgo (Alto / Medio / Bajo).  
    - Campos sensibles identificados.  
    - Opciones: *Ocultar* o *Enviar de todos modos*.  

- **Servidor backend (FastAPI)**  
  - Endpoints:  
    - `/detect` â†’ analiza texto plano.  
    - `/detect_file` â†’ analiza PDFs (extracciÃ³n de texto con `pdfplumber`, `PyPDF2`, `pdfminer`, OCR opcional).  
  - ComunicaciÃ³n entre extensiÃ³n y modelo de detecciÃ³n.  
  - Respuesta en formato **JSON estructurado**.  

- **DetecciÃ³n de datos sensibles**  
  - Uso de un LLM (por defecto `OpenAI/gpt-oss-120B` vÃ­a API de **Groq**).  
  - Soporte para mÃºltiples modos de anÃ¡lisis (*Zero-shot*, *Few-shot*â€¦).  
  - CategorizaciÃ³n de campos en **riesgo alto**, **medio** o **bajo**.  
  - Ejemplos: credenciales, nÃºmeros de tarjeta, correos electrÃ³nicos, direcciones, telÃ©fonos, identificadores personales, etc.  

- **Experimentos con 5 LLMs**  
  - Modelos evaluados:  
    - GPT-4o-mini  
    - Gemini 1.5 Pro  
    - OpenAI/gpt-oss-120B  
    - LLaMA 4 Scout 17B 16E Instruct  
    - Claude-3 Haiku  
  - ComparaciÃ³n de precisiÃ³n, exhaustividad y robustez en la tarea de detecciÃ³n de datos sensibles.  
  - Scripts y resultados disponibles en la carpeta `TEST/`.

---

## ğŸ“‚ Estructura del repositorio

### ğŸ“‚ `LLM_Guard_Extension/`

Contiene la implementaciÃ³n de la extensiÃ³n y el backend.

```text
LLM_Guard_Extension/
â”œâ”€â”€ FastAPI.py
â”œâ”€â”€ server.py
â”œâ”€â”€ extension/                  
â”‚   â”œâ”€â”€ content.js              # Script inyectado en ChatGPT
â”‚   â”œâ”€â”€ icon128.png             # Icono de la extensiÃ³n
â”‚   â””â”€â”€ manifest.json           # ConfiguraciÃ³n de la extensiÃ³n
â”œâ”€â”€ server/                     
â”‚   â”œâ”€â”€ app.py                  # Servidor FastAPI con endpoints /detect y /detect_file
â”‚   â”œâ”€â”€ detector_gpt_4o_mini.py # Detector usando GPT-4o-mini
â”‚   â”œâ”€â”€ detector_gpt_oss_120b.py# Detector usando gpt-oss-120B
â”‚   â”œâ”€â”€ PROMPTS/                # Plantillas de prompts
â”‚   â”‚   â”œâ”€â”€ FS_prompt.txt
â”‚   â”‚   â”œâ”€â”€ ZS_enriquecido_prompt.txt
â”‚   â”‚   â””â”€â”€ ZS_prompt.txt
â”‚   â””â”€â”€ __pycache__/            # Archivos compilados de Python

TEST/
â”œâ”€â”€ chatgpt_wrapper.py          # Wrapper para interactuar con ChatGPT
â”œâ”€â”€ english_pii_43k.jsonl       # Dataset con ejemplos sensibles en inglÃ©s
â”œâ”€â”€ evaluation.py               # Script principal de evaluaciÃ³n
â”œâ”€â”€ Middleware.py               # Funciones de soporte
â”œâ”€â”€ UI.py                       # Interfaz de usuario bÃ¡sica
â”œâ”€â”€ CLAUDE/                     # Experimentos con Claude-3 Haiku
â”‚   â”œâ”€â”€ claude-3-haiku.py
â”‚   â”œâ”€â”€ pii_detection_sample_claude-3-haiku_1000_FS.json
â”‚   â”œâ”€â”€ pii_detection_sample_claude_ZS_1000.json
â”‚   â””â”€â”€ pii_detection_sample_claude_ZS_enriquecido_1000.json
â”œâ”€â”€ GEMINI/                     # Experimentos con Gemini 1.5 Pro
â”‚   â”œâ”€â”€ gemini1.5-pro.py
â”‚   â”œâ”€â”€ pii_detection_sample_Gemini_1.5pro_FS_1000.json
â”‚   â”œâ”€â”€ pii_detection_sample_Gemini_1.5pro_ZS_enriquecido_1000.json
â”‚   â””â”€â”€ pii_detection_sample_Gemini_1.5_pro_ZS_1000.json
â”œâ”€â”€ GPT-4o-MINI/                # Experimentos con GPT-4o-mini
â”‚   â”œâ”€â”€ gpt_4o_mini.py
â”‚   â”œâ”€â”€ pii_detection_sample_gpt-4o-mini_FS.json
â”‚   â”œâ”€â”€ pii_detection_sample_gpt_4o_mini_1000_ZS_enriquecido.json
â”‚   â””â”€â”€ pii_detection_sample_gpt_4o_mini_ZS_1000.json
â”œâ”€â”€ GPT-OSS-120b/               # Experimentos con gpt-oss-120B
â”‚   â”œâ”€â”€ gpt_oss_120_ZS.py
â”‚   â”œâ”€â”€ pii_detection_sample_gpt_oss_120b_FS.json
â”‚   â”œâ”€â”€ pii_detection_sample_gpt_oss_120b_ZS_1000.json
â”‚   â””â”€â”€ pii_detection_sample_gpt_oss_120b_ZS_enriquecido_1000.json
â””â”€â”€ LLAMA/                      # Experimentos con LLaMA 4 Scout 17B 16E Instruct
    â”œâ”€â”€ llama4_scout_17b_16e_instruct.py
    â”œâ”€â”€ pii_detection_sample_llama4_scout_FS.json
    â”œâ”€â”€ pii_detection_sample_llama4_scout_ZS_1000.json
    â””â”€â”€ pii_detection_sample_llama4_scout_ZS_enriquecido_1000.json

